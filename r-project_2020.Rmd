---
title: "R-project-2020"
author: "Kilian DEBRAUX Anthony QUERE"
date: "17/11/2020"
output: pdf_document
---

```{r setup, include=FALSE}
DATASET_DIR="../datasets/"
posts <- read.csv(paste(DATASET_DIR, "Posts.csv", sep=""), sep = ",")
tags <- read.csv(paste(DATASET_DIR, "Tags.csv", sep=""), sep = ",")
library(dplyr)
library(stringr)
library(questionr)

# mise en forme des données
row.names(tags) <- tags$TagName
tags$nb <- rep(0, nrow(tags))
tags$nb_rep <- rep(0, nrow(tags))
tags$rep_pond <- rep(0, nrow(tags))
tags$nb_re_a <- rep(0, nrow(tags))
tags$rep_pond_a <- rep(0, nrow(tags))

posts_2 <- subset(posts, PostTypeId == 1)

knitr::opts_chunk$set(echo = TRUE)
```

![logo](logo.png)

Stack overflow est un site web de type forum permettant de poser ses questions à une communauté. Celle ci est principalement composée de développeurs. Nous avons obtennu nos données depuis __[Les archives de stackexchange](https://archive.org/details/stackexchange)__ (https://archive.org/details/stackexchange). Notre jeu de donnée a été réduit à 300 000 donnéespour être utilisable  réparties sur 3 mois entre Août et Septembre 2020.


> Nous avons rencontré des problèmes avec notre jeu de donnée. 
> Nous avons commencer à exploiter un jeu de donnée de la même source mais il s'est révélé incohérent et peu réaliste. 
> Nous avons hélas mis beaucoup de temps à le remarquer et nous avons alors été confronté à un second problème.
> Le fichier que nous voulions était bien sur cette plateforme mais sous un autre nom et hélas u autre poids. 
> Nous nous sommes donc retrouvés avec une archive de 15.6Go à télécharger avec de faibles connexions. 
> Le premier téléchargement a échoué à la toute fin après de nombreuses heures mais nous avons rééssayé en passant cette fois ci par un *curl* et nous avons enfin eu les données dans un fichier de plus de 80 Go; nous l'avons bien sûr réduit.
> Nous avons eu très peu de temps entre ce moment et l'heure de rendu, nous esperons que vous pourrez en prendre considération pendant votre correction. Nous tenons à nous excuser pour la gêne occasionnée

## Les technologies populaires
Cette fonction permet de récupérer des posts en fonction de tags mis sous forme de vecteur de regex
```{r}
get_posts_by_tag <- function(dataset, tags) {
  regexes = paste("<", tags, ">", sep = "")
  posts <- c()
  for (r in regexes) {
    p <- subset(dataset, grepl(r, Tags))$Id
    posts <- union(posts, p)
  }
  return(posts)
}


# get only questions posts 
questions <- subset(posts, PostTypeId == "1")
```

### Les tags le plus populaires

```{r}

sortedTags <- tags[order(tags$Count, decreasing = TRUE),]

TAGS_NUMBER = 10

mostPopularTags = head(sortedTags, n = TAGS_NUMBER)
lessPopularTags = tail(sortedTags, n = nrow(sortedTags) - TAGS_NUMBER)

otherValue = sum(lessPopularTags$Count)

pie(c(mostPopularTags$Count, otherValue), c(mostPopularTags$TagName, "Others"))

```
Nous avons pu récupérer le contenue de ce jeu de donnée car bien plus légé que le fichier principal. Nous pouvons constater par ce graphique que les tags les plus présents concèrenent essentielement les technologies du web (**Javascript**, **Php**, **HTML** et **CSS**; les autres technologies peuvent aussi servir en web comme le **Java** avec le framework *Spring* ou le **C#** avec *.net*). Nous avons choisi de n'en nommer que 10 pour des soucis de clarté. Ce diagramme nous permet de voir aisément les problématiques principales de la plateforme.

### Les frameworks front-end
Les technologies évoluant contement en raison des besoins différents de chaque entreprise, plusieurs d'entre elles rendent disponibles des frameworks. Côté Front-End, on en retrouve 5 principaux : **Angular**, **Angular.js** (il est important de les distinguer car ils n'ont pas du tout le même fonctionnement), **React.js**, **Vue.js** et **JQuery**. Nous voulons maintenant définir un "leader du marché" et montrer leurs différences de popularité.

```{r}

angularRegex = c("angular", "angular[2-9]", "angular10")

angularjsRegex = c("angularjs", "angular1.6")

reactRegex = c("reactjs")

vueRegex = c("vue.js", "vuejs2")

jqueryRegex = c("jquery")

angularPosts <- get_posts_by_tag(questions, angularRegex)
angularjsPosts <- get_posts_by_tag(questions, angularjsRegex)
reactPosts <- get_posts_by_tag(questions, reactRegex)
vuePosts <- get_posts_by_tag(questions, vueRegex)
jqueryPosts <- get_posts_by_tag(questions, jqueryRegex)

i <- c(length(angularPosts), length(angularjsPosts), length(reactPosts), length(vuePosts), length(jqueryPosts))
l <- c("Angular", "Angular.js", "React.js", "Vue.js", "JQuery")

pie(i, l)
```

Nous pouvons constater que les frameworks **React** et **Angular** sont très appréciés par la communauté aujourd'hui, d'autant plus react qui a pour aventage d'être très efficace et maitrisable en peu de temps, Angular a plus de fonctionnalités de base (comme *RxJs*) mais est sur certains points plus complexe.  On retrouve ensuite le **Jquery** ce qui n'est pas très étonnant étant donné que c'est un framework simple qui est encore beaucoup utilisé dans de nombreux sites même s'il utilise aujourd'hui certaines fonctionnalités dépréciées. **Vue.js** est aussi très présent, c'est un framework simple et légé mais bien moins populaire que React et Angular. Nous avons choisi d'ajouter également **Angular.js** car il existe un débat Angular contre **Angular Js**. Angular.js, aussi appelé *Angular 1* est la version de base du projet Angular qui a connu un changement de langage en arrivant en version 2; **Angular** utilise du *Typescript* et **Angular.js** du *Javascript*, une partie de la communauté préfère rester sur du javascript.


### Les distributions linux

```{r}

ubuntuRegex = c("ubuntu", "ubuntu-[1-2][0-9]-[0-9][0-9]")

centosRegex = c("centos", "centos[0-9]")

redhatRegex = c("redhat")

debianRegex = c("debian")

fedoraRegex = c("fedora", "fedora-[0-9]", "fedora-[0-9][0-9]")


ubuntuPosts <- get_posts_by_tag(questions, ubuntuRegex)
centosPosts <- get_posts_by_tag(questions, centosRegex)
redhatPosts <- get_posts_by_tag(questions, redhatRegex)
debianPosts <- get_posts_by_tag(questions, debianRegex)
fedoraPosts <- get_posts_by_tag(questions, fedoraRegex)

i <- c(length(ubuntuPosts), length(centosPosts), length(redhatPosts), length(debianPosts), length(fedoraPosts))
l <- c("Ubuntu", "Centos", "RedHat", "Debian", "Fedora")

pie(i, l)
```


Malgré notre choix de proposer 2 distributions basées sur Debian et 3 sur Centos, nous constatons une très grande préférence pour les distributions basées sur Debian à savoir **Debian** et **Ubuntu**. C'est le résultat que nous attendions car ces distributions linux sont très utilisées par la communauté pour leur utilisation personnelle. Les distributions issues de **Centos** (sauf **Fedora**) sont bien plus utilisées en leur version server, donc avec uniquement la *command line*, dans un contexte d'entreprise, c'est pourquoi on le retrouve en moins grande majorité.


### Les langages de programmation

```{r}

cRegex = c("c")

csRegex = c("c#")

cppRegex = c("c\\+\\+")

pythonRegex = c("python")

javaRegex = c("java")

dartRegex = c("dart")

jsRegex = c("javascript")

tsRegex = c("typescript")

rubyRegex = c("ruby")

phpRegex = c("php")


cPosts <- get_posts_by_tag(questions, cRegex)
csPosts <- get_posts_by_tag(questions, csRegex)
cppPosts <- get_posts_by_tag(questions, cppRegex)
pythonPosts <- get_posts_by_tag(questions, pythonRegex)
javaPosts <- get_posts_by_tag(questions, javaRegex)
dartPosts <- get_posts_by_tag(questions, dartRegex)
jsPosts <- get_posts_by_tag(questions, jsRegex)
tsPosts <- get_posts_by_tag(questions, tsRegex)
rubyPosts <- get_posts_by_tag(questions, rubyRegex)
phpPosts <- get_posts_by_tag(questions, phpRegex)

i <- c(length(cPosts), length(csPosts), length(cppPosts), length(pythonPosts), length(javaPosts), length(dartPosts), length(jsPosts), length(tsPosts), length(rubyPosts), length(phpPosts))
l <- c("C", "C#", "C++", "Python", "Java", "Dart", "Javascript", "Typescript", "Ruby", "Php")

pie(i, l)
```

On les langages les plus présents sur ce diagramme sont le **Python** et le **Javascript**. Ce sont des langages très polivalents, le **Javascript** est un obligtoire du web Front-End et peut être utilisé également comme Back-End. De la même manière le **Python** peu être utilisé aussi bien pour du web Back-End, de l'automatisation, de l'inteligence artificielle... Le java a pour aventage qu'un même code peut être utilisable sur Windows, Linux et Mac, de plus c'est un langage natif pour Android. Le **C#** est utilisé en web avec .net mais aussi dans le monde du jeu vidéo. Le php est encore massivement utilisé en web Back-End même si la tendance est largement en baisse depuis de nombreuses années au profit du **Java* avec *Spring* , du **Python** avec *Django*, du **Javascript** avec *Node...*

### Les IDE (Environnement de développement)
```{r}

vscRegex = c("visual\\-studio\\-code")

vsRegex = c("visual\\-studio")

eclipseRegex = c("eclipse")

atomRegex = c("atom\\-editor")

intellijRegex = c("intellij\\-idea")

sublRegex = c("sublimetext[1-3]?")


vscPosts <- get_posts_by_tag(questions, vscRegex)
vsPosts <- get_posts_by_tag(questions, vsRegex)
eclipsePosts <- get_posts_by_tag(questions, eclipseRegex)
atomPosts <- get_posts_by_tag(questions, atomRegex)
intellijPosts <- get_posts_by_tag(questions, intellijRegex)
sublPosts <- get_posts_by_tag(questions, sublRegex)

i <- c(length(vscPosts), length(vsPosts), length(eclipsePosts), length(atomPosts), length(intellijPosts), length(sublPosts))
l <- c("Visual Studio Code", "Visual Studio", "Eclipse", "Atom", "Intellij", "Sublim Text")

pie(i, l)
```

On remarque directement la dominance des ide de microsoft **Visual Studio** et **Visual Studio Code**. Le premier est essentiellement utilisé pourdévelopper en C, C# et C++ et le second est de très loin l'ide le plus populaire. Il peut être utilisé pour pratiquement tous les langages et frameworks et est très adaptable avec de nombreux plugins pour utiliser Git, Docker, R, ... In tellij est aussi très populaire, dans a version IDEA il peut même être plus puisant que Visual Studio Code sous certains aspets notement dans le dévelppement d'appliations regroupant plusieurs technologies comme une API en Spring, un client en React et une base de donnée PostgreSQL, cependant il est payant et donc moins utilisé. Eclipse est très utilisé pour le java mais l'entreprise a de moins en moins de succès et cet ide est de moins en mois utilisé. Atom et Visual Studio Code ressemblent à Visual Studio Code mais permettent moins de choses.


# Problématique

Sur stackoverflow, on pose une question, et des gens nous répondent. C'est ainsi que l'on peut être aidé dans la résolution d'un problème si quelqu'un d'autre voit notre réponse.

Pour classifier les différentes questions, on peut leur ajouter des tags, c'est à dire des mots clés qui permettent de trouver facilement le post. Par exemple, on a le tag "bug", ce tag peut être ajouté à tous les post qui demande à ce qu'on résolve un bug dans un programme. Ainsi, les codeur qui veulent aider d'autre peuvent faire une recherche des posts contenant ce tag et essayer d'aider l'auteur.

Ainsi, on peut penser que certains tags sont plus susceptible d'attirer l'attention de gens voulant aider (comme le tag "bug", ou "help-center")

C'est ce que nous allons nous demander : Quels tags sont le plus susceptibles de nous apporter des réponses ?

Attention, on pourrait prendre cette étude pour un classement des tags à mettre pour être aider. Or non, il faut bien sûr que le tag corresponde au sujet (ou vous ne serez pas aidé), mais il faut bien vérifier que votre demande rentre dans les tags que nous allons voir car, si c'est le cas, vous pourrez être aidé plus rapidement.


## répartition des tags dans stackoverflow

La première chose que nous devrions étudier est la répartition des différents tags dans le site. Si certains sont plus utilisés que d'autres, il faudra prendre ça en compte dans nos statistiques. De plus nous pourrons voir si les tags qui apportent le plus de réponses sont ceux les plus utilisés ou au contraire l'inverse.

```{r}
tagsSortMostUsed <- tags[order(tags$Count, decreasing = TRUE),]
# tableau de féquence des tags pour faire apparaître les 10 tags les plus utilisés
tagsFreqPlus <- tagsSortMostUsed[1:10,]
# affichage des piecharts
pie(c(tagsFreqPlus$Count, sum(tags$Count) - sum(tagsFreqPlus$Count)), labels = c(row.names(tagsFreqPlus), "others"), main = "Graphique de répartition des 10 tags les plus utilisés", col = c("#0077ff", "#9e68f2", "#df54d6", "#ff46b0", "#ff4c87", "#ff665e", "#ff8636", "#ffa600"), radius = 1, cex=0.5)
```

Voici la répartition des tags. Ce graphique n'est pas très lisible, du au fait que l'on arrive très vite à des tags qui représentent moins de 1% en tout (ici, tous les tags qui représentent moins de 1% des posts sont dans "others"). Pour y vois plus clair, nous allons prendre uniquement les tags qui représentent plus de 1% (ceux qui sont affichés au dessus à part "others"). Comme la répartition ici n'est pas importante (puisque nous avons que les 10 premiers), nous allons faire un barlplot.

```{r}
barplot(tagsFreqPlus$Count ~ row.names(tagsFreqPlus), main = "Graphique du nombre de posts en fonction des tags contenus", col = c("#0077ff", "#9e68f2", "#df54d6", "#ff46b0", "#ff4c87", "#ff665e", "#ff8636", "#ffa600"), las=2, xlab="", ylab="")
```
Ce graphique est plus lisible, mais nous avons encore du réduire la police des labels pour qu'il le soit.

On peut donc enfin voir les tags les plus utilisés, Cela pourra nous être utile par la suite pour nos analyses.


## analyse du nombre de réponses en fonction des tags

Maintenant, pour savoir quels tags sont susceptibles de nous aider, il faut savoir lesquels apportent le plus de réponses. En effet, plus les gens répondent à notre post, plus nous avons de chances de trouver la solution à notre problème. Pour cela, nous allons compter combien il existe de réponses pour chaque tags (comme il existe beaucoup de tags, nous n'allons charger que les 100 plus populaires) :

```{r}
# récupération du nombre de réponses par posts

tagsSortMostUsed[,4] <- rep(0, nrow(tagsSortMostUsed))

parsedTags = str_replace_all(tagsSortMostUsed$TagName, c("[\\+]"), "\\\\+")
parsedTags = str_replace_all(parsedTags, "(\\-)", "\\\\-")

get_posts_by_tag <- function(dataset, tags) {
  regexes = paste("<", tags, ">", sep = "")
  posts <- c()
  for (r in regexes) {
    posts <- subset(dataset, grepl(r, Tags))
  }
  return(posts)
}

for (tag in parsedTags[1:100]){
  realTag = str_replace_all(tag, c("\\\\+"), "")
  realTag = str_replace_all(realTag, "(\\\\-)", "\\-")
  posts_with_tag = get_posts_by_tag(posts, tag)
  tagsSortMostUsed[realTag,4] <- sum(posts_with_tag$AnswerCount)
}

```

Une fois les données récupérées, on peut les afficher, il risque d'y avoir beaucoup de données à afficher, on va donc afficher les 10 premiers tags qui ont le plus de réponses, sous forme de barplot pour avoir une échelle de comparaison entre les tags :

```{r}
tagstenrep <- tagsSortMostUsed[order(tagsSortMostUsed$nb_rep, decreasing = TRUE),]
barplot(tagstenrep$nb_rep[1:10] ~ row.names(tagstenrep[1:10,]), main = "Graphique des 10 tags avec le plus de réponses", col = c("#0077ff", "#9e68f2", "#df54d6", "#ff46b0", "#ff4c87", "#ff665e", "#ff8636", "#ffa600"), las=2, xlab="", ylab="")
```

On voit sur ce graphe les 10 tags les plus répondus, et il est très proche des 10 tags les plus utilisés. C'est normal, on compte les réponses sur les posts avec tel ou tel tag. Or plus il y a de posts avec un tag, plus ce tag aura de réponses. Il faut alors diviser le nombre de réponses avec un tag par le nombre de posts avec ce tag pour avoir quelque chose de concluant. Cependant, on voit des changement, comme sql qui est très répondu alors qu'il n'est pas dans les 10 les plus utilisés, ou python qui est le plus répondu alors qu'il n'est "que" 3ème dans les plus utilisés.

Pour avoir une meilleure vue des plus répondu, on va diviser le nombre de réponse par tags par le nombre d'utilisation. Et afficher le graphique en baton des 10 tags les plus répondus, pondérés par le nombre de posts.

```{r}
# récupération du nombre de réponses pondérée par le nombre de posts
tagsSortMostUsed[1:100, 5] <- (tagsSortMostUsed[1:100, 4] / tagsSortMostUsed[1:100, 2])

tagstenpond <- tagsSortMostUsed[order(tagsSortMostUsed$rep_pond, decreasing = TRUE),]
barplot(tagstenpond$rep_pond[1:10] ~ row.names(tagstenpond[1:10,]), main = "Graphique pondéré des tags avec le plus de réponses", col = c("#0077ff", "#9e68f2", "#df54d6", "#ff46b0", "#ff4c87", "#ff665e", "#ff8636", "#ffa600"), las=2, xlab = "", ylab = "")

```

En regardant le graphique, on voit que les tags les plus répondus sont beaucoup différents des tags les plus utilisés que ce que l'on aurait pu penser avec l'autre graphique. Il n'y a aucun tag en commum. Cependant, on voit quand même des choses populaires : par exemple on retrouve reactjs, qui est le framework front le plus mentionner (cf. le comparatif des framework front-end).

Voici, en opposition la liste des tags avec le moins de réponses pondérées par le nombre de posts, pour voir quels sont les tags qui n'apportent pas beaucoup de réponses :

```{r}
tagsdata <- tagsSortMostUsed[1:100,]
tagsdata[order(tagsdata$rep_pond),]
```

On voit dans ce tableau des tags les moins répondus quelque chose d'interessant : angularjs et python-2.7 sont des technologies vielles ou en tout cas plus utilisées, ce qui peut expliqué le faible taux de réponses (il est bon de rappeler que ces données sont celle de aout et septembre 2020). D'autres tags peu utilisés semble être du au fait qu'ils soient des concepts propriétaires (non en libre droit), comme iphone ou asp.net (qui appartient respactivement à apple et microsoft).

Cependant, ce n'est pas parce que l'on a des réponses que l'on a notre solution au problème. Pour remédier à cela, il est possible, sur stackoverflow, de marquer une réponse comme étant celle qui nous a aidé. On peut donc regarder quels tags ont le plus de réponses acceptées.

## analyse du nombre de réponses acceptées en fonction des tags

Pour analyser cela, nous allons récupérer les posts qui ont une réponse acceptée, puis compter leurs tags et faire afficher un graphique de la fréquence de ces tags.

```{r}
tagsSortMostUsed[,6] <- rep(0, nrow(tagsSortMostUsed))
posts_2$AcceptedAnswerCount <- posts_2$AcceptedAnswerId / posts_2$AcceptedAnswerId
posts_2$AcceptedAnswerCount[is.na(posts_2$AcceptedAnswerCount)] <- 0

parsedTags = str_replace_all(tagsSortMostUsed$TagName, c("[\\+]"), "\\\\+")
parsedTags = str_replace_all(parsedTags, "(\\-)", "\\\\-")

for (tag in parsedTags[1:100]){
  realTag = str_replace_all(tag, c("\\\\+"), "")
  realTag = str_replace_all(realTag, "(\\\\-)", "\\-")
  posts_with_tag = get_posts_by_tag(posts, tag)
  tagsSortMostUsed[realTag,6] <- sum(posts_with_tag$AcceptedAnswerCount)
}

tagstenaccepted <- tagsSortMostUsed[order(tagsSortMostUsed$nb_re_a, decreasing = TRUE),]
barplot(tagstenaccepted$rep_pond[1:10] ~ row.names(tagstenaccepted[1:10,]), main = "Graphique des tags avec le plus de réponses acceptées", col = c("#0077ff", "#9e68f2", "#df54d6", "#ff46b0", "#ff4c87", "#ff665e", "#ff8636", "#ffa600"), las=2, xlab = "", ylab = "")
```


Sur ce graphique, on remarque des similudes avec le graphe des réponses générales. C'est normal, plus on a de réponses, plus on a de chance d'en avoir une acceptée. Cependant, on voit par exemple le langage R qui a beaucoup de réponses acceptées mais pas autant de réponses.

Néanmoins, nous ne pondérons pas les réponses acceptées par le nombre de posts, ce qui peut encore fausser quelque peu les résultats. Pour remédier à cela, comme avant, on va diviser le nombre de réponses acceptées par le nombre de posts de chaque tags.

```{r}
# récupération du nombre de réponses acceptées pondérée par le nombre de posts
for (i in row.names(tagsSortMostUsed[1:100,])){
  tagsSortMostUsed[i, 7] <- tagsSortMostUsed[i, 6] / tagsSortMostUsed[i, 2]
}

tagstenpond <- tagsSortMostUsed[order(tagsSortMostUsed$rep_pond_a, decreasing = TRUE),]
barplot(tagstenpond$rep_pond_a[1:10] ~ row.names(tagstenpond[1:10,]), main = "Graphique pondéré des tags avec le plus de réponses acceptées", col = c("#0077ff", "#9e68f2", "#df54d6", "#ff46b0", "#ff4c87", "#ff665e", "#ff8636", "#ffa600"), las=2, xlab = "", ylab = "")
```

On peut donc voir ici les 10 labels qui ont le plus de réponses acceptés. On a encore une fois des similitude avec le précédent graphique, mais l'on voit l'arriver de nouveaux tags comme docker ou web-services.

Pour notre information, voici la liste des tags avec le moins de réponses acceptées. On voit qu'il y a beaucoup de tags qui sont très utilisés. On peut imaginer qu'un tag très utilisé a donc moins de chance d'avoir des réponses acceptées que les autres.

```{r}
tagsdata <- tagsSortMostUsed[1:100,]
tagsdata[order(tagsdata$rep_pond_a),]
```
On peut voir que les tags avec le moins de réponses acceptées sont les tags avec le moins de réponses tout court (à une exception près). On peut donc en déduire que ces tags sont très peu utiles en 2020.


Pour conclure, nous aimerions ajouté que cette étude ne sert à savoir quel tag mettre pour être aidé. Il faut toujours mettre des tags qui correspondent au besoin du post. Cependant nous avons pu voir les tags les plus importants, donc si votre post rentre dans l'un deux, il serait dommage de passer à côté


# Implication dans le projet

## Kilian DEBRAUX

J'ai participé avec Anthony à écrire le parser, et j'ai aussi écrit le paragraphe décrivant le parser. 

Pour ce qui est des statistiques, j'ai écrit la partie sur les l'importance des tags pour être aidé. J'ai trouvé que l'idée pouvait être utile pour savoir quels tags permettaient le plus de répondre à nos problèmes. Pour cela j'ai donc utiliser le parser XML pour convertir les fichiers sur les tags et sur les posts en csv et pouvoir les importer dans R studio. Ensuite, j'ai utiliser R afin de d'obtenir des statistiques sur les réponses par tags.  

Pour cela j'ai beaucoup utilisé la documentation R pour rechercher des informations sur les fonctions. Notamment les fonction pour les Regex (str_match_all), ce qui permet de récupérer facilement une chaine de caractère au milieu d'un texte (ici de récupérer la valeur d'un tag entre chevron : "<tag>" qui devient "tag"). De plus cela m'a permis aussi de beaucoup utiliser les boucles, ce que je n'avait pas eu besoin de faire lors des TP.




































